{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 🧬 X1: merging quantile-normalized bed + bigwig ===\n",
      "📘 Loaded bed=(18268, 511), bigwig=(18268, 175)\n",
      "✅ Merged shape: (18268, 679)\n",
      "💾 Saved → ../preprocessed_data/reference/1. merged data/without_y_5000_one_side/X1_all_logzscore_logzscore.tsv\n",
      "\n",
      "=== 🧬 X2: merging quantile-normalized bed + bigwig ===\n",
      "📘 Loaded bed=(18268, 511), bigwig=(18268, 175)\n",
      "✅ Merged shape: (18268, 679)\n",
      "💾 Saved → ../preprocessed_data/reference/1. merged data/without_y_5000_one_side/X2_all_logzscore_logzscore.tsv\n",
      "\n",
      "=== 🧬 X3: merging quantile-normalized bed + bigwig ===\n",
      "⚠️ Missing bigwig file: ../preprocessed_data/reference/0. data/bigwig5000_one_side/X3_logzscore.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "#                  基本設定\n",
    "# ============================================================\n",
    "base_dir = \"../preprocessed_data/reference/0. data\"\n",
    "bed_dir = os.path.join(base_dir, \"bed5250\")\n",
    "bed_norm_suffix = 'logzscore'  # or zscore, raw\n",
    "\n",
    "\n",
    "bw_dir = os.path.join(base_dir, \"bigwig250\")\n",
    "bw_norm_suffix = 'logzscore'  # bigwig 檔案的正規化後綴\n",
    "\n",
    "output_dir = \"../preprocessed_data/reference/1. merged data/without_y_250/\"  # 合併輸出在這層\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "cells = [\"X1\", \"X2\", \"X3\"]\n",
    "\n",
    "# 要去除的欄位\n",
    "drop_cols = [\"chr\", \"gene_start\", \"gene_end\", \"TSS_start\", \"TSS_end\", \"strand\"]\n",
    "\n",
    "# ============================================================\n",
    "#                  逐 cell line 合併\n",
    "# ============================================================\n",
    "for cell in cells:\n",
    "    bed_path = os.path.join(bed_dir, f\"{cell}_{bed_norm_suffix}.tsv\")\n",
    "    bw_path = os.path.join(bw_dir, f\"{cell}_{bw_norm_suffix}.tsv\")\n",
    "    out_path = os.path.join(output_dir, f\"{cell}_all_{bed_norm_suffix}_{bw_norm_suffix}.tsv\")\n",
    "\n",
    "    print(f\"\\n=== 🧬 {cell}: merging quantile-normalized bed + bigwig ===\")\n",
    "\n",
    "    if not os.path.exists(bed_path):\n",
    "        print(f\"⚠️ Missing bed file: {bed_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(bw_path):\n",
    "        print(f\"⚠️ Missing bigwig file: {bw_path}\")\n",
    "        continue\n",
    "\n",
    "    # --- 讀取 ---\n",
    "    df_bed = pd.read_csv(bed_path, sep=\"\\t\")\n",
    "    df_bw = pd.read_csv(bw_path, sep=\"\\t\")\n",
    "\n",
    "    if \"gene_name\" not in df_bed.columns or \"gene_name\" not in df_bw.columns:\n",
    "        raise ValueError(f\"❌ Missing 'gene_name' column in {cell}\")\n",
    "\n",
    "    print(f\"📘 Loaded bed={df_bed.shape}, bigwig={df_bw.shape}\")\n",
    "\n",
    "    # --- 去掉不需要的欄位 ---\n",
    "    keep_cols = [c for c in df_bed.columns if c not in drop_cols]\n",
    "    df_bed = df_bed[keep_cols]\n",
    "\n",
    "    # --- 合併 ---\n",
    "    df_merged = pd.merge(df_bed, df_bw, on=\"gene_name\", how=\"outer\")\n",
    "    print(f\"✅ Merged shape: {df_merged.shape}\")\n",
    "\n",
    "    # --- 儲存 ---\n",
    "    df_merged.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"💾 Saved → {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 🧬 X1: dense normalized rank (0–1) + merge with QN ===\n",
      "📘 Loaded y=(16284, 3), qn=(18268, 679)\n",
      "✅ Merged shape: (16284, 681)\n",
      "💾 Saved → ../preprocessed_data/reference/1. merged data/with_y_5000_one_side/X1_all_logzscore_logzscore_with_y.tsv\n",
      "\n",
      "=== 🧬 X2: dense normalized rank (0–1) + merge with QN ===\n",
      "📘 Loaded y=(16284, 3), qn=(18268, 679)\n",
      "✅ Merged shape: (16284, 681)\n",
      "💾 Saved → ../preprocessed_data/reference/1. merged data/with_y_5000_one_side/X2_all_logzscore_logzscore_with_y.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "#                  基本設定\n",
    "# ============================================================\n",
    "y_dir = \"../preprocessed_data/reference/0. data/\"\n",
    "features_dir = \"../preprocessed_data/reference/1. merged data/without_y_250\"\n",
    "output_dir = \"../preprocessed_data/reference/1. merged data/with_y_250\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "cells = [\"X1\", \"X2\"]\n",
    "\n",
    "# 這兩個 suffix 記得根據實際命名設定\n",
    "bed_norm_suffix = \"logzscore\"\n",
    "bw_norm_suffix = \"logzscore\"\n",
    "\n",
    "# ============================================================\n",
    "#                  主流程\n",
    "# ============================================================\n",
    "for cell in cells:\n",
    "    y_path = os.path.join(y_dir, f\"{cell}_y.tsv\")\n",
    "    qn_path = os.path.join(features_dir, f\"{cell}_all_{bed_norm_suffix}_{bw_norm_suffix}.tsv\")\n",
    "    out_path = os.path.join(output_dir, f\"{cell}_all_{bed_norm_suffix}_{bw_norm_suffix}_with_y.tsv\")\n",
    "\n",
    "    print(f\"\\n=== 🧬 {cell}: dense normalized rank (0–1) + merge with QN ===\")\n",
    "\n",
    "    if not os.path.exists(y_path):\n",
    "        print(f\"⚠️ Missing Y file: {y_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(qn_path):\n",
    "        print(f\"⚠️ Missing QN file: {qn_path}\")\n",
    "        continue\n",
    "\n",
    "    # --- 讀取 ---\n",
    "    df_y = pd.read_csv(y_path, sep=\"\\t\")\n",
    "    df_qn = pd.read_csv(qn_path, sep=\"\\t\")\n",
    "\n",
    "    if \"gene_name\" not in df_y.columns or \"gene_name\" not in df_qn.columns:\n",
    "        raise ValueError(f\"❌ Missing 'gene_name' column in {cell}\")\n",
    "    if \"gex\" not in df_y.columns:\n",
    "        raise ValueError(f\"❌ Missing 'gex' column in {cell}_y.tsv\")\n",
    "\n",
    "    print(f\"📘 Loaded y={df_y.shape}, qn={df_qn.shape}\")\n",
    "\n",
    "    # --- 以 df_y 為主進行合併 ---\n",
    "    df_merged = pd.merge(df_y, df_qn, on=\"gene_name\", how=\"left\")\n",
    "\n",
    "    print(f\"✅ Merged shape: {df_merged.shape}\")\n",
    "\n",
    "    # --- 輸出 ---\n",
    "    df_merged.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"💾 Saved → {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 🧬 X1: dense normalized rank (0–1) + merge with QN ===\n",
      "📘 Loaded y=(16284, 3), qn=(18268, 175)\n",
      "✅ Merged shape: (16284, 177)\n",
      "💾 Saved → ../preprocessed_data/reference/1. merged data/with_y_500_only_bi_one_side/X1_logzscore_with_y.tsv\n",
      "\n",
      "=== 🧬 X2: dense normalized rank (0–1) + merge with QN ===\n",
      "📘 Loaded y=(16284, 3), qn=(18268, 175)\n",
      "✅ Merged shape: (16284, 177)\n",
      "💾 Saved → ../preprocessed_data/reference/1. merged data/with_y_500_only_bi_one_side/X2_logzscore_with_y.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "#                  基本設定\n",
    "# ============================================================\n",
    "#                  基本設定\n",
    "# ============================================================\n",
    "y_dir = \"../preprocessed_data/reference/0. data/\"\n",
    "features_dir = \"../preprocessed_data/reference/0. data/bigwig500_one_side/\"\n",
    "output_dir = \"../preprocessed_data/reference/1. merged data/with_y_500_only_bi_one_side\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "cells = [\"X1\", \"X2\"]\n",
    "\n",
    "# 這兩個 suffix 記得根據實際命名設定\n",
    "norm_suffix = \"logzscore\"\n",
    "\n",
    "# ============================================================\n",
    "#                  主流程\n",
    "# ============================================================\n",
    "for cell in cells:\n",
    "    y_path = os.path.join(y_dir, f\"{cell}_y.tsv\")\n",
    "    qn_path = os.path.join(features_dir, f\"{cell}_{norm_suffix}.tsv\")\n",
    "    out_path = os.path.join(output_dir, f\"{cell}_{norm_suffix}_with_y.tsv\")\n",
    "\n",
    "    print(f\"\\n=== 🧬 {cell}: dense normalized rank (0–1) + merge with QN ===\")\n",
    "\n",
    "    if not os.path.exists(y_path):\n",
    "        print(f\"⚠️ Missing Y file: {y_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(qn_path):\n",
    "        print(f\"⚠️ Missing QN file: {qn_path}\")\n",
    "        continue\n",
    "\n",
    "    # --- 讀取 ---\n",
    "    df_y = pd.read_csv(y_path, sep=\"\\t\")\n",
    "    df_qn = pd.read_csv(qn_path, sep=\"\\t\")\n",
    "\n",
    "    if \"gene_name\" not in df_y.columns or \"gene_name\" not in df_qn.columns:\n",
    "        raise ValueError(f\"❌ Missing 'gene_name' column in {cell}\")\n",
    "    if \"gex\" not in df_y.columns:\n",
    "        raise ValueError(f\"❌ Missing 'gex' column in {cell}_y.tsv\")\n",
    "\n",
    "    print(f\"📘 Loaded y={df_y.shape}, qn={df_qn.shape}\")\n",
    "\n",
    "    # --- 以 df_y 為主進行合併 ---\n",
    "    df_merged = pd.merge(df_y, df_qn, on=\"gene_name\", how=\"left\")\n",
    "\n",
    "    print(f\"✅ Merged shape: {df_merged.shape}\")\n",
    "\n",
    "    # --- 輸出 ---\n",
    "    df_merged.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"💾 Saved → {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
