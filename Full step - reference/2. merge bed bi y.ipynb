{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ğŸ§¬ X1: merging quantile-normalized bed + bigwig ===\n",
      "ğŸ“˜ Loaded bed=(18268, 511), bigwig=(18268, 175)\n",
      "âœ… Merged shape: (18268, 679)\n",
      "ğŸ’¾ Saved â†’ ../preprocessed_data/reference/1. merged data/without_y_5000_one_side/X1_all_logzscore_logzscore.tsv\n",
      "\n",
      "=== ğŸ§¬ X2: merging quantile-normalized bed + bigwig ===\n",
      "ğŸ“˜ Loaded bed=(18268, 511), bigwig=(18268, 175)\n",
      "âœ… Merged shape: (18268, 679)\n",
      "ğŸ’¾ Saved â†’ ../preprocessed_data/reference/1. merged data/without_y_5000_one_side/X2_all_logzscore_logzscore.tsv\n",
      "\n",
      "=== ğŸ§¬ X3: merging quantile-normalized bed + bigwig ===\n",
      "âš ï¸ Missing bigwig file: ../preprocessed_data/reference/0. data/bigwig5000_one_side/X3_logzscore.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "#                  åŸºæœ¬è¨­å®š\n",
    "# ============================================================\n",
    "base_dir = \"../preprocessed_data/reference/0. data\"\n",
    "bed_dir = os.path.join(base_dir, \"bed5250\")\n",
    "bed_norm_suffix = 'logzscore'  # or zscore, raw\n",
    "\n",
    "\n",
    "bw_dir = os.path.join(base_dir, \"bigwig250\")\n",
    "bw_norm_suffix = 'logzscore'  # bigwig æª”æ¡ˆçš„æ­£è¦åŒ–å¾Œç¶´\n",
    "\n",
    "output_dir = \"../preprocessed_data/reference/1. merged data/without_y_250/\"  # åˆä½µè¼¸å‡ºåœ¨é€™å±¤\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "cells = [\"X1\", \"X2\", \"X3\"]\n",
    "\n",
    "# è¦å»é™¤çš„æ¬„ä½\n",
    "drop_cols = [\"chr\", \"gene_start\", \"gene_end\", \"TSS_start\", \"TSS_end\", \"strand\"]\n",
    "\n",
    "# ============================================================\n",
    "#                  é€ cell line åˆä½µ\n",
    "# ============================================================\n",
    "for cell in cells:\n",
    "    bed_path = os.path.join(bed_dir, f\"{cell}_{bed_norm_suffix}.tsv\")\n",
    "    bw_path = os.path.join(bw_dir, f\"{cell}_{bw_norm_suffix}.tsv\")\n",
    "    out_path = os.path.join(output_dir, f\"{cell}_all_{bed_norm_suffix}_{bw_norm_suffix}.tsv\")\n",
    "\n",
    "    print(f\"\\n=== ğŸ§¬ {cell}: merging quantile-normalized bed + bigwig ===\")\n",
    "\n",
    "    if not os.path.exists(bed_path):\n",
    "        print(f\"âš ï¸ Missing bed file: {bed_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(bw_path):\n",
    "        print(f\"âš ï¸ Missing bigwig file: {bw_path}\")\n",
    "        continue\n",
    "\n",
    "    # --- è®€å– ---\n",
    "    df_bed = pd.read_csv(bed_path, sep=\"\\t\")\n",
    "    df_bw = pd.read_csv(bw_path, sep=\"\\t\")\n",
    "\n",
    "    if \"gene_name\" not in df_bed.columns or \"gene_name\" not in df_bw.columns:\n",
    "        raise ValueError(f\"âŒ Missing 'gene_name' column in {cell}\")\n",
    "\n",
    "    print(f\"ğŸ“˜ Loaded bed={df_bed.shape}, bigwig={df_bw.shape}\")\n",
    "\n",
    "    # --- å»æ‰ä¸éœ€è¦çš„æ¬„ä½ ---\n",
    "    keep_cols = [c for c in df_bed.columns if c not in drop_cols]\n",
    "    df_bed = df_bed[keep_cols]\n",
    "\n",
    "    # --- åˆä½µ ---\n",
    "    df_merged = pd.merge(df_bed, df_bw, on=\"gene_name\", how=\"outer\")\n",
    "    print(f\"âœ… Merged shape: {df_merged.shape}\")\n",
    "\n",
    "    # --- å„²å­˜ ---\n",
    "    df_merged.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"ğŸ’¾ Saved â†’ {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ğŸ§¬ X1: dense normalized rank (0â€“1) + merge with QN ===\n",
      "ğŸ“˜ Loaded y=(16284, 3), qn=(18268, 679)\n",
      "âœ… Merged shape: (16284, 681)\n",
      "ğŸ’¾ Saved â†’ ../preprocessed_data/reference/1. merged data/with_y_5000_one_side/X1_all_logzscore_logzscore_with_y.tsv\n",
      "\n",
      "=== ğŸ§¬ X2: dense normalized rank (0â€“1) + merge with QN ===\n",
      "ğŸ“˜ Loaded y=(16284, 3), qn=(18268, 679)\n",
      "âœ… Merged shape: (16284, 681)\n",
      "ğŸ’¾ Saved â†’ ../preprocessed_data/reference/1. merged data/with_y_5000_one_side/X2_all_logzscore_logzscore_with_y.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "#                  åŸºæœ¬è¨­å®š\n",
    "# ============================================================\n",
    "y_dir = \"../preprocessed_data/reference/0. data/\"\n",
    "features_dir = \"../preprocessed_data/reference/1. merged data/without_y_250\"\n",
    "output_dir = \"../preprocessed_data/reference/1. merged data/with_y_250\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "cells = [\"X1\", \"X2\"]\n",
    "\n",
    "# é€™å…©å€‹ suffix è¨˜å¾—æ ¹æ“šå¯¦éš›å‘½åè¨­å®š\n",
    "bed_norm_suffix = \"logzscore\"\n",
    "bw_norm_suffix = \"logzscore\"\n",
    "\n",
    "# ============================================================\n",
    "#                  ä¸»æµç¨‹\n",
    "# ============================================================\n",
    "for cell in cells:\n",
    "    y_path = os.path.join(y_dir, f\"{cell}_y.tsv\")\n",
    "    qn_path = os.path.join(features_dir, f\"{cell}_all_{bed_norm_suffix}_{bw_norm_suffix}.tsv\")\n",
    "    out_path = os.path.join(output_dir, f\"{cell}_all_{bed_norm_suffix}_{bw_norm_suffix}_with_y.tsv\")\n",
    "\n",
    "    print(f\"\\n=== ğŸ§¬ {cell}: dense normalized rank (0â€“1) + merge with QN ===\")\n",
    "\n",
    "    if not os.path.exists(y_path):\n",
    "        print(f\"âš ï¸ Missing Y file: {y_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(qn_path):\n",
    "        print(f\"âš ï¸ Missing QN file: {qn_path}\")\n",
    "        continue\n",
    "\n",
    "    # --- è®€å– ---\n",
    "    df_y = pd.read_csv(y_path, sep=\"\\t\")\n",
    "    df_qn = pd.read_csv(qn_path, sep=\"\\t\")\n",
    "\n",
    "    if \"gene_name\" not in df_y.columns or \"gene_name\" not in df_qn.columns:\n",
    "        raise ValueError(f\"âŒ Missing 'gene_name' column in {cell}\")\n",
    "    if \"gex\" not in df_y.columns:\n",
    "        raise ValueError(f\"âŒ Missing 'gex' column in {cell}_y.tsv\")\n",
    "\n",
    "    print(f\"ğŸ“˜ Loaded y={df_y.shape}, qn={df_qn.shape}\")\n",
    "\n",
    "    # --- ä»¥ df_y ç‚ºä¸»é€²è¡Œåˆä½µ ---\n",
    "    df_merged = pd.merge(df_y, df_qn, on=\"gene_name\", how=\"left\")\n",
    "\n",
    "    print(f\"âœ… Merged shape: {df_merged.shape}\")\n",
    "\n",
    "    # --- è¼¸å‡º ---\n",
    "    df_merged.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"ğŸ’¾ Saved â†’ {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ğŸ§¬ X1: dense normalized rank (0â€“1) + merge with QN ===\n",
      "ğŸ“˜ Loaded y=(16284, 3), qn=(18268, 175)\n",
      "âœ… Merged shape: (16284, 177)\n",
      "ğŸ’¾ Saved â†’ ../preprocessed_data/reference/1. merged data/with_y_500_only_bi_one_side/X1_logzscore_with_y.tsv\n",
      "\n",
      "=== ğŸ§¬ X2: dense normalized rank (0â€“1) + merge with QN ===\n",
      "ğŸ“˜ Loaded y=(16284, 3), qn=(18268, 175)\n",
      "âœ… Merged shape: (16284, 177)\n",
      "ğŸ’¾ Saved â†’ ../preprocessed_data/reference/1. merged data/with_y_500_only_bi_one_side/X2_logzscore_with_y.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "#                  åŸºæœ¬è¨­å®š\n",
    "# ============================================================\n",
    "#                  åŸºæœ¬è¨­å®š\n",
    "# ============================================================\n",
    "y_dir = \"../preprocessed_data/reference/0. data/\"\n",
    "features_dir = \"../preprocessed_data/reference/0. data/bigwig500_one_side/\"\n",
    "output_dir = \"../preprocessed_data/reference/1. merged data/with_y_500_only_bi_one_side\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "cells = [\"X1\", \"X2\"]\n",
    "\n",
    "# é€™å…©å€‹ suffix è¨˜å¾—æ ¹æ“šå¯¦éš›å‘½åè¨­å®š\n",
    "norm_suffix = \"logzscore\"\n",
    "\n",
    "# ============================================================\n",
    "#                  ä¸»æµç¨‹\n",
    "# ============================================================\n",
    "for cell in cells:\n",
    "    y_path = os.path.join(y_dir, f\"{cell}_y.tsv\")\n",
    "    qn_path = os.path.join(features_dir, f\"{cell}_{norm_suffix}.tsv\")\n",
    "    out_path = os.path.join(output_dir, f\"{cell}_{norm_suffix}_with_y.tsv\")\n",
    "\n",
    "    print(f\"\\n=== ğŸ§¬ {cell}: dense normalized rank (0â€“1) + merge with QN ===\")\n",
    "\n",
    "    if not os.path.exists(y_path):\n",
    "        print(f\"âš ï¸ Missing Y file: {y_path}\")\n",
    "        continue\n",
    "    if not os.path.exists(qn_path):\n",
    "        print(f\"âš ï¸ Missing QN file: {qn_path}\")\n",
    "        continue\n",
    "\n",
    "    # --- è®€å– ---\n",
    "    df_y = pd.read_csv(y_path, sep=\"\\t\")\n",
    "    df_qn = pd.read_csv(qn_path, sep=\"\\t\")\n",
    "\n",
    "    if \"gene_name\" not in df_y.columns or \"gene_name\" not in df_qn.columns:\n",
    "        raise ValueError(f\"âŒ Missing 'gene_name' column in {cell}\")\n",
    "    if \"gex\" not in df_y.columns:\n",
    "        raise ValueError(f\"âŒ Missing 'gex' column in {cell}_y.tsv\")\n",
    "\n",
    "    print(f\"ğŸ“˜ Loaded y={df_y.shape}, qn={df_qn.shape}\")\n",
    "\n",
    "    # --- ä»¥ df_y ç‚ºä¸»é€²è¡Œåˆä½µ ---\n",
    "    df_merged = pd.merge(df_y, df_qn, on=\"gene_name\", how=\"left\")\n",
    "\n",
    "    print(f\"âœ… Merged shape: {df_merged.shape}\")\n",
    "\n",
    "    # --- è¼¸å‡º ---\n",
    "    df_merged.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"ğŸ’¾ Saved â†’ {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
