{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged train+val and merged info and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# === 自然排序函式 ===\n",
    "def chr_sort_key(chr_name):\n",
    "    m = re.match(r\"chr(\\d+)\", chr_name)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    elif chr_name == \"chrX\":\n",
    "        return 23\n",
    "    elif chr_name == \"chrY\":\n",
    "        return 24\n",
    "    else:\n",
    "        return 100  # 其他 contigs (random, Un, etc.)\n",
    "\n",
    "# === 路徑設定 ===\n",
    "base = r\"C:\\Users\\wani\\Desktop\\Courses\\ML for genomics\\ML4G_Project_1_Data\\CAGE-train\\CAGE-train\"\n",
    "out_folder = r\"C:\\Users\\wani\\Desktop\\Courses\\ML for genomics\\preprocessed_data\\CAGE-merged\"\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "# === 處理 X1, X2 ===\n",
    "for cell in [\"X1\", \"X2\"]:\n",
    "    print(f\"\\n🔹 Processing {cell} ...\")\n",
    "\n",
    "    # 讀取 info\n",
    "    info_train = pd.read_csv(os.path.join(base, f\"{cell}_train_info.tsv\"), sep=\"\\t\")\n",
    "    info_val = pd.read_csv(os.path.join(base, f\"{cell}_val_info.tsv\"), sep=\"\\t\")\n",
    "    info_merged = pd.concat([info_train, info_val], ignore_index=True)\n",
    "\n",
    "    # 讀取 y\n",
    "    y_train = pd.read_csv(os.path.join(base, f\"{cell}_train_y.tsv\"), sep=\"\\t\")\n",
    "    y_val = pd.read_csv(os.path.join(base, f\"{cell}_val_y.tsv\"), sep=\"\\t\")\n",
    "    y_merged = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "    if y_merged.shape[1] == 2:\n",
    "        y_merged.columns = [\"gene_name\", \"gex\"]\n",
    "    else:\n",
    "        y_merged.columns = [\"gex\"]\n",
    "        y_merged.insert(0, \"gene_name\", info_merged[\"gene_name\"])\n",
    "\n",
    "    merged = pd.merge(info_merged, y_merged, on=\"gene_name\", how=\"inner\")\n",
    "\n",
    "    # 儲存結果\n",
    "    merged_path = os.path.join(out_folder, f\"{cell}_merged.tsv\")\n",
    "    merged.to_csv(merged_path, sep=\"\\t\", index=False)\n",
    "    print(f\"✅ Saved merged file: {merged_path} ({len(merged)} genes)\")\n",
    "\n",
    "    # 印出排序後的 chr 名稱\n",
    "    if \"chr\" in merged.columns:\n",
    "        unique_chrs = sorted(merged[\"chr\"].unique(), key=chr_sort_key)\n",
    "        print(f\"🧬 {cell} unique chromosomes ({len(unique_chrs)}):\")\n",
    "        print(\", \".join(unique_chrs))\n",
    "    else:\n",
    "        print(f\"⚠️ Column 'chr' not found in merged file for {cell}!\")\n",
    "\n",
    "print(\"\\n🎯 All cell lines merged successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Marks z-score stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧬 Processing cell line: X1\n",
      "\n",
      "📂 Reading DNase (X1) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/16284 [00:00<02:45, 98.10it/s]/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_13009/2748442008.py:103: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  sharpness = kurtosis(vals) if len(vals) > 3 else np.nan\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_13009/2748442008.py:104: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  asymmetry = skew(vals) if len(vals) > 3 else np.nan\n",
      "/opt/anaconda3/envs/ml4g_project1/lib/python3.12/site-packages/numpy/lib/_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      " 14%|█▍        | 2304/16284 [00:16<01:42, 136.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_13009/2748442008.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    197\u001b[39m                         d[k].append(np.nan)\n\u001b[32m    198\u001b[39m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    199\u001b[39m \n\u001b[32m    200\u001b[39m             \u001b[38;5;66;03m# === Gene body ===\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m             g_stats = region_zsignal(\n\u001b[32m    202\u001b[39m                 bw, chrom, row[\u001b[33m\"gene_start\"\u001b[39m], row[\u001b[33m\"gene_end\"\u001b[39m],\n\u001b[32m    203\u001b[39m                 global_mean, global_std,\n\u001b[32m    204\u001b[39m                 mark_name=mark, cell_name=cell\n",
      "\u001b[32m/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_13009/2748442008.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(bw, chrom, start, end, global_mean, global_std, mark_name, cell_name)\u001b[39m\n\u001b[32m    100\u001b[39m     slope = np.polyfit(x, vals, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m len(vals) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np.nan\n\u001b[32m    101\u001b[39m \n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# === 7️⃣ Shape-based Descriptors ===\u001b[39;00m\n\u001b[32m    103\u001b[39m     sharpness = kurtosis(vals) \u001b[38;5;28;01mif\u001b[39;00m len(vals) > \u001b[32m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np.nan\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     asymmetry = skew(vals) \u001b[38;5;28;01mif\u001b[39;00m len(vals) > \u001b[32m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np.nan\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# === 8️⃣ Entropy / Complexity ===\u001b[39;00m\n\u001b[32m    107\u001b[39m     p = np.abs(vals)\n",
      "\u001b[32m/opt/anaconda3/envs/ml4g_project1/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    575\u001b[39m                     res = np.full(n_out, NaN)\n\u001b[32m    576\u001b[39m                     res = _add_reduced_axes(res, reduced_axes, keepdims)\n\u001b[32m    577\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m tuple_to_result(*res)\n\u001b[32m    578\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m                 res = hypotest_fun_out(*samples, **kwds)\n\u001b[32m    580\u001b[39m                 res = result_to_tuple(res, n_out)\n\u001b[32m    581\u001b[39m                 res = _add_reduced_axes(res, reduced_axes, keepdims)\n\u001b[32m    582\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m tuple_to_result(*res)\n",
      "\u001b[32m/opt/anaconda3/envs/ml4g_project1/lib/python3.12/site-packages/scipy/stats/_stats_py.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(a, axis, bias, nan_policy)\u001b[39m\n\u001b[32m   1343\u001b[39m     \u001b[32m0.2650554122698573\u001b[39m\n\u001b[32m   1344\u001b[39m \n\u001b[32m   1345\u001b[39m     \"\"\"\n\u001b[32m   1346\u001b[39m     xp = array_namespace(a)\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m     a, axis = _chk_asarray(a, axis, xp=xp)\n\u001b[32m   1348\u001b[39m     n = _length_nonmasked(a, axis, xp=xp)\n\u001b[32m   1349\u001b[39m \n\u001b[32m   1350\u001b[39m     mean = xp.mean(a, axis=axis, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m/opt/anaconda3/envs/ml4g_project1/lib/python3.12/site-packages/scipy/stats/_stats_py.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(a, axis, xp)\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m _chk_asarray(a, axis, *, xp=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xp \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    118\u001b[39m         xp = array_namespace(a)\n\u001b[32m    119\u001b[39m \n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyBigWig\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === 基本設定 ===\n",
    "base = \"/Users/deweywang/Desktop/GitHub/Gene-expression-prediction/ML4G_Project_1_Data\"\n",
    "merged_base = \"/Users/deweywang/Desktop/GitHub/Gene-expression-prediction/preprocessed_data/CAGE-merged\"\n",
    "stats_path = \"/Users/deweywang/Desktop/GitHub/Gene-expression-prediction/preprocessed_data/global_norm_stats.json\"\n",
    "\n",
    "marks = [\"DNase\", \"H3K27ac\", \"H3K4me3\", \"H3K27me3\", \"H3K36me3\", \"H3K4me1\", \"H3K9me3\"]\n",
    "tss_window = 1000  # +/- 1kb 區域作為 promoter 區域\n",
    "cells = {\n",
    "    \"X1\": os.path.join(merged_base, \"X1_merged.tsv\"),\n",
    "    \"X2\": os.path.join(merged_base, \"X2_merged.tsv\"),\n",
    "    \"X3\": os.path.join(base, \"CAGE-train/CAGE-train/X3_test_info.tsv\"),\n",
    "}\n",
    "\n",
    "# === 載入 global normalization 統計 ===\n",
    "with open(stats_path, \"r\") as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "# === 輔助函式 ===\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "from numpy.fft import fft\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "\n",
    "def region_zsignal(bw, chrom, start, end, global_mean, global_std, mark_name=None, cell_name=None):\n",
    "    \"\"\"\n",
    "    取出 bigWig 區域的多層級 z-score 特徵：\n",
    "    1️⃣ Mean/Std/Min/Max/Diff\n",
    "    2️⃣ Signal Gradient / Derivative Features\n",
    "    3️⃣ Shape-based Descriptors (Kurtosis, Skewness)\n",
    "    4️⃣ Entropy / Complexity\n",
    "    5️⃣ Spatial Autocorrelation / Smoothness\n",
    "    ⚙️ 所有 NaN / inf / 無效區域均會設為 0.0，保證輸出穩定。\n",
    "    \"\"\"\n",
    "\n",
    "    feature_keys = [\n",
    "        \"z_mean\", \"z_std\", \"z_min\", \"z_max\", \"z_diff\",\n",
    "        \"gradient_mean\", \"slope\", \"kurtosis\", \"skewness\",\n",
    "        \"entropy\", \"autocorr\", \"laplacian\"\n",
    "    ]\n",
    "\n",
    "    chroms = bw.chroms()\n",
    "\n",
    "    # === 1️⃣ 染色體不存在 ===\n",
    "    if chrom not in chroms:\n",
    "        print(f\"⚠️ [region_zsignal] Missing chromosome {chrom} in {mark_name or '?'} ({cell_name or '?'}) → fill 0.0\")\n",
    "        return {k: 0.0 for k in feature_keys}\n",
    "\n",
    "    chrom_length = chroms[chrom]\n",
    "    start = max(0, int(start))\n",
    "    end = min(int(end), chrom_length)\n",
    "\n",
    "    # === 2️⃣ 無效區域 ===\n",
    "    if end <= start:\n",
    "        print(f\"⚠️ [region_zsignal] Invalid region {chrom}:{start}-{end} (end <= start) in {mark_name or '?'} → fill 0.0\")\n",
    "        return {k: 0.0 for k in feature_keys}\n",
    "\n",
    "    # === 3️⃣ 取值 ===\n",
    "    vals = np.array(bw.values(chrom, start, end, numpy=True))\n",
    "    if vals is None or len(vals) == 0:\n",
    "        print(f\"⚠️ [region_zsignal] Empty values for {chrom}:{start}-{end} in {mark_name or '?'} → fill 0.0\")\n",
    "        return {k: 0.0 for k in feature_keys}\n",
    "\n",
    "    vals = vals[~np.isnan(vals)]\n",
    "    if len(vals) == 0:\n",
    "        print(f\"⚠️ [region_zsignal] All NaN values for {chrom}:{start}-{end} in {mark_name or '?'} → fill 0.0\")\n",
    "        return {k: 0.0 for k in feature_keys}\n",
    "\n",
    "    # === 4️⃣ 計算統計量 ===\n",
    "    local_mean = np.mean(vals)\n",
    "    local_std  = np.std(vals)\n",
    "    local_min  = np.min(vals)\n",
    "    local_max  = np.max(vals)\n",
    "    local_diff = local_max - local_min\n",
    "\n",
    "    # === Z-score normalization ===\n",
    "    z_mean = (local_mean - global_mean) / (global_std + 1e-8)\n",
    "    z_std  = local_std / (global_std + 1e-8)\n",
    "    z_min  = (local_min - global_mean) / (global_std + 1e-8)\n",
    "    z_max  = (local_max - global_mean) / (global_std + 1e-8)\n",
    "    z_diff = z_max - z_min\n",
    "\n",
    "    # === 5️⃣ 處理 inf/nan 結果 ===\n",
    "    for name in [\"z_mean\", \"z_std\", \"z_min\", \"z_max\", \"z_diff\"]:\n",
    "        val = locals()[name]\n",
    "        if not np.isfinite(val):\n",
    "            print(f\"⚠️ [region_zsignal] {name} not finite ({val}) for {chrom}:{start}-{end} in {mark_name or '?'} → set to 0\")\n",
    "            locals()[name] = 0.0\n",
    "\n",
    "    # === 6️⃣ Signal Gradient / Slope ===\n",
    "    if len(vals) > 1:\n",
    "        diffs = np.diff(vals)\n",
    "        gradient_mean = np.mean(np.abs(diffs)) if len(diffs) > 0 else 0.0\n",
    "        x = np.arange(len(vals))\n",
    "        try:\n",
    "            slope = np.polyfit(x, vals, 1)[0]\n",
    "        except Exception:\n",
    "            slope = 0.0\n",
    "    else:\n",
    "        gradient_mean, slope = 0.0, 0.0\n",
    "\n",
    "    # === 7️⃣ Shape-based Descriptors ===\n",
    "    sharpness = kurtosis(vals) if len(vals) > 3 else 0.0\n",
    "    asymmetry = skew(vals) if len(vals) > 3 else 0.0\n",
    "\n",
    "    # === 8️⃣ Entropy / Complexity ===\n",
    "    p = np.abs(vals)\n",
    "    if p.sum() == 0:\n",
    "        local_entropy = 0.0\n",
    "    else:\n",
    "        p = p / (p.sum() + 1e-8)\n",
    "        local_entropy = -np.sum(p * np.log2(p + 1e-8))\n",
    "\n",
    "    # === 9️⃣ Spatial Autocorrelation / Smoothness ===\n",
    "    if len(vals) > 2:\n",
    "        try:\n",
    "            autocorr = np.corrcoef(vals[:-1], vals[1:])[0, 1]\n",
    "        except Exception:\n",
    "            autocorr = 0.0\n",
    "    else:\n",
    "        autocorr = 0.0\n",
    "\n",
    "    if len(vals) > 3:\n",
    "        laplacian = np.mean(np.abs(vals[:-2] - 2 * vals[1:-1] + vals[2:]))\n",
    "    else:\n",
    "        laplacian = 0.0\n",
    "\n",
    "    # === 10️⃣ 確保所有結果有限 ===\n",
    "    result = {\n",
    "        \"z_mean\": z_mean,\n",
    "        \"z_std\": z_std,\n",
    "        \"z_min\": z_min,\n",
    "        \"z_max\": z_max,\n",
    "        \"z_diff\": z_diff,\n",
    "        \"gradient_mean\": gradient_mean,\n",
    "        \"slope\": slope,\n",
    "        \"kurtosis\": sharpness,\n",
    "        \"skewness\": asymmetry,\n",
    "        \"entropy\": local_entropy,\n",
    "        \"autocorr\": autocorr,\n",
    "        \"laplacian\": laplacian,\n",
    "    }\n",
    "\n",
    "    for k, v in result.items():\n",
    "        if not np.isfinite(v):\n",
    "            result[k] = 0.0\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_tss_region(row, window=1000):\n",
    "    \"\"\"根據 strand (+/-) 給出 promoter (TSS ± window) 區域\"\"\"\n",
    "    if row[\"strand\"] == \"+\":\n",
    "        start = max(0, row[\"TSS_start\"] - window)\n",
    "        end = row[\"TSS_end\"]\n",
    "    else:  # strand == \"-\"\n",
    "        start = row[\"TSS_start\"]\n",
    "        end = row[\"TSS_end\"] + window\n",
    "    return start, end\n",
    "\n",
    "\n",
    "# === 主迴圈：對每個 cell line 做 ===\n",
    "# === 主迴圈：對每個 cell line 做 ===\n",
    "for cell, merged_path in cells.items():\n",
    "    if not os.path.exists(merged_path):\n",
    "        print(f\"⚠️ Missing file for {cell}: {merged_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🧬 Processing cell line: {cell}\")\n",
    "    genes = pd.read_csv(merged_path, sep=\"\\t\")\n",
    "\n",
    "    # 避免 test 沒有 gex 欄位出錯\n",
    "    if \"gex\" not in genes.columns:\n",
    "        genes[\"gex\"] = np.nan\n",
    "\n",
    "    # === 對每個 mark 做特徵提取 ===\n",
    "    for mark in marks:\n",
    "        bw_path = os.path.join(base, f\"{mark}-bigwig\", f\"{cell}.bw\")\n",
    "        if not os.path.exists(bw_path):\n",
    "            bw_path = os.path.join(base, f\"{mark}-bigwig\", f\"{cell}.bigwig\")\n",
    "        if not os.path.exists(bw_path):\n",
    "            print(f\"⚠️ Missing {mark} ({cell})\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n📂 Reading {mark} ({cell}) ...\")\n",
    "        bw = pyBigWig.open(bw_path)\n",
    "        chroms = bw.chroms()\n",
    "\n",
    "        key = f\"{mark}_{cell}\"\n",
    "        if key not in stats:\n",
    "            print(f\"⚠️ No global stat found for {key}\")\n",
    "            continue\n",
    "\n",
    "        global_mean = stats[key][\"mean\"]\n",
    "        global_std = stats[key][\"std\"]\n",
    "\n",
    "        # === 建立空字典儲存所有 feature ===\n",
    "        gene_features = {f\"{mark}_gene_{k}\": [] for k in [\n",
    "            \"z_mean\", \"z_std\", \"z_min\", \"z_max\", \"z_diff\",\n",
    "            \"gradient_mean\", \"slope\", \"kurtosis\", \"skewness\",\n",
    "            \"entropy\", \"autocorr\", \"laplacian\"\n",
    "        ]}\n",
    "        tss_features = {f\"{mark}_tss_{k}\": [] for k in [\n",
    "            \"z_mean\", \"z_std\", \"z_min\", \"z_max\", \"z_diff\",\n",
    "            \"gradient_mean\", \"slope\", \"kurtosis\", \"skewness\",\n",
    "            \"entropy\", \"autocorr\", \"laplacian\"\n",
    "        ]}\n",
    "\n",
    "        # === 主迴圈：對每個基因計算 ===\n",
    "        for _, row in tqdm(genes.iterrows(), total=len(genes)):\n",
    "            chrom = row[\"chr\"]\n",
    "            if chrom not in chroms:\n",
    "                for d in (gene_features, tss_features):\n",
    "                    for k in d.keys():\n",
    "                        d[k].append(np.nan)\n",
    "                continue\n",
    "\n",
    "            # === Gene body ===\n",
    "            g_stats = region_zsignal(\n",
    "                bw, chrom, row[\"gene_start\"], row[\"gene_end\"],\n",
    "                global_mean, global_std,\n",
    "                mark_name=mark, cell_name=cell\n",
    "            )\n",
    "            for k, v in g_stats.items():\n",
    "                gene_features[f\"{mark}_gene_{k}\"].append(v)\n",
    "\n",
    "            # === TSS / promoter ===\n",
    "            tss_start, tss_end = get_tss_region(row, window=tss_window)\n",
    "            t_stats = region_zsignal(\n",
    "                bw, chrom, tss_start, tss_end,\n",
    "                global_mean, global_std,\n",
    "                mark_name=mark, cell_name=cell\n",
    "            )\n",
    "            for k, v in t_stats.items():\n",
    "                tss_features[f\"{mark}_tss_{k}\"].append(v)\n",
    "\n",
    "        bw.close()\n",
    "\n",
    "        # === 合併進 DataFrame ===\n",
    "        for feat_dict in (gene_features, tss_features):\n",
    "            for col, vals in feat_dict.items():\n",
    "                genes[col] = vals\n",
    "\n",
    "    # === 輸出結果 ===\n",
    "    out_path = os.path.join(merged_base, f\"{cell}_zscore_dynamics.tsv\")\n",
    "    genes.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"\\n✅ Saved dynamic z-score features for {cell} → {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6️⃣ Cross-mark dynamics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
