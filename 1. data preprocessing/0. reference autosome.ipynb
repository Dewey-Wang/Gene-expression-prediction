{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged train+val and merged info and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 rows: 16284, X2 rows: 16284\n",
      "âœ… X1 and X2 gene metadata are COMPLETELY identical.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# è·¯å¾‘è¨­å®š\n",
    "# ============================================================\n",
    "base = \"../ML4G_Project_1_Data/CAGE-train/CAGE-train\"\n",
    "\n",
    "files = {\n",
    "    \"X1_train\": os.path.join(base, \"X1_train_info.tsv\"),\n",
    "    \"X1_val\":   os.path.join(base, \"X1_val_info.tsv\"),\n",
    "    \"X2_train\": os.path.join(base, \"X2_train_info.tsv\"),\n",
    "    \"X2_val\":   os.path.join(base, \"X2_val_info.tsv\"),\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# è¼‰å…¥ä¸¦åˆä½µ X1 / X2\n",
    "# ============================================================\n",
    "def load_and_concat(train_path, val_path):\n",
    "    df_train = pd.read_csv(train_path, sep=\"\\t\")\n",
    "    df_val = pd.read_csv(val_path, sep=\"\\t\")\n",
    "    df = pd.concat([df_train, df_val], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "df_X1 = load_and_concat(files[\"X1_train\"], files[\"X1_val\"])\n",
    "df_X2 = load_and_concat(files[\"X2_train\"], files[\"X2_val\"])\n",
    "\n",
    "# ============================================================\n",
    "# æŒ‡å®šè¦æ¯”è¼ƒçš„æ¬„ä½\n",
    "# ============================================================\n",
    "cols_to_check = [\"gene_name\", \"chr\", \"gene_start\", \"gene_end\", \"TSS_start\", \"TSS_end\", \"strand\"]\n",
    "\n",
    "df1 = df_X1[cols_to_check].copy().reset_index(drop=True)\n",
    "df2 = df_X2[cols_to_check].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"X1 rows: {len(df1)}, X2 rows: {len(df2)}\")\n",
    "\n",
    "# ============================================================\n",
    "# æ¯”è¼ƒè³‡æ–™åˆ—æ˜¯å¦å®Œå…¨ä¸€è‡´\n",
    "# ============================================================\n",
    "# æ–¹æ³•1ï¼šç›´æ¥ç”¨ pandas.equals()\n",
    "same_structure = df1.equals(df2)\n",
    "\n",
    "if same_structure:\n",
    "    print(\"âœ… X1 and X2 gene metadata are COMPLETELY identical.\")\n",
    "else:\n",
    "    print(\"âŒ Differences found between X1 and X2 gene annotations.\")\n",
    "\n",
    "    # æª¢æŸ¥å·®ç•°ç­†æ•¸èˆ‡ gene_name ä¸åŒä¹‹è™•\n",
    "    merged = df1.merge(df2, on=cols_to_check, how=\"outer\", indicator=True)\n",
    "    diff = merged[merged[\"_merge\"] != \"both\"]\n",
    "\n",
    "    print(f\"âš ï¸ Number of differing entries: {len(diff)}\")\n",
    "    print(\"Sample differences:\")\n",
    "    print(diff.head(10))\n",
    "\n",
    "    # å¦‚æœä½ åªæƒ³çŸ¥é“å“ªé‚Šå°‘äº†å“ªäº›åŸºå› ï¼š\n",
    "    missing_in_X2 = df1.merge(df2, on=cols_to_check, how=\"left\", indicator=True)\n",
    "    missing_in_X2 = missing_in_X2[missing_in_X2[\"_merge\"] == \"left_only\"]\n",
    "    print(f\"\\nğŸ§© Genes in X1 but not in X2: {len(missing_in_X2)}\")\n",
    "    print(missing_in_X2.head())\n",
    "\n",
    "    missing_in_X1 = df2.merge(df1, on=cols_to_check, how=\"left\", indicator=True)\n",
    "    missing_in_X1 = missing_in_X1[missing_in_X1[\"_merge\"] == \"left_only\"]\n",
    "    print(f\"\\nğŸ§© Genes in X2 but not in X1: {len(missing_in_X1)}\")\n",
    "    print(missing_in_X1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded: X1(16284), X2(16284), X3(1984)\n",
      "ğŸ”— Merged X1 & X2: 16284 entries\n",
      "ğŸ“˜ Unified reference length (X1+X2): 16284\n",
      "ğŸ§© Final unified reference (with X3): 18268\n",
      "âœ… Saved reference table â†’ ../preprocessed_data/CAGE-merged/reference_gene_table.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# è·¯å¾‘è¨­å®š\n",
    "# ============================================================\n",
    "base = \"../ML4G_Project_1_Data/CAGE-train/CAGE-train\"\n",
    "\n",
    "X1_train = os.path.join(base, \"X1_train_info.tsv\")\n",
    "X1_val   = os.path.join(base, \"X1_val_info.tsv\")\n",
    "X2_train = os.path.join(base, \"X2_train_info.tsv\")\n",
    "X2_val   = os.path.join(base, \"X2_val_info.tsv\")\n",
    "X3_test  = os.path.join(base, \"X3_test_info.tsv\")\n",
    "\n",
    "# ============================================================\n",
    "# è¼‰å…¥èˆ‡åˆä½µ\n",
    "# ============================================================\n",
    "def load_concat(train, val):\n",
    "    df1 = pd.read_csv(train, sep=\"\\t\")\n",
    "    df2 = pd.read_csv(val, sep=\"\\t\")\n",
    "    return pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df_X1 = load_concat(X1_train, X1_val)\n",
    "df_X2 = load_concat(X2_train, X2_val)\n",
    "df_X3 = pd.read_csv(X3_test, sep=\"\\t\")\n",
    "\n",
    "print(f\"âœ… Loaded: X1({len(df_X1)}), X2({len(df_X2)}), X3({len(df_X3)})\")\n",
    "\n",
    "# ============================================================\n",
    "# æº–å‚™åˆä½µç”¨çš„ key\n",
    "# ============================================================\n",
    "merge_keys = [\"gene_name\", \"chr\", \"gene_start\", \"gene_end\", \"strand\"]\n",
    "\n",
    "merged = df_X1.merge(\n",
    "    df_X2,\n",
    "    on=merge_keys,\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_X1\", \"_X2\"),\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸ”— Merged X1 & X2: {len(merged)} entries\")\n",
    "\n",
    "# ============================================================\n",
    "# è‹¥å…©è€… TSS ä¸åŒ â†’ ç”¨ min/max çµ±ä¸€\n",
    "# ============================================================\n",
    "def pick_reference(row):\n",
    "    # è‹¥æœ‰ç¼ºå€¼ (æŸåŸºå› åªå‡ºç¾åœ¨ä¸€é‚Š)ï¼Œå–å­˜åœ¨çš„å€¼\n",
    "    tss_start_1, tss_start_2 = row.get(\"TSS_start_X1\"), row.get(\"TSS_start_X2\")\n",
    "    tss_end_1, tss_end_2 = row.get(\"TSS_end_X1\"), row.get(\"TSS_end_X2\")\n",
    "\n",
    "    # å°‡ç¼ºå¤±å€¼è¦–ç‚º NaN è™•ç†\n",
    "    tss_start_1 = pd.to_numeric(tss_start_1, errors=\"coerce\")\n",
    "    tss_start_2 = pd.to_numeric(tss_start_2, errors=\"coerce\")\n",
    "    tss_end_1 = pd.to_numeric(tss_end_1, errors=\"coerce\")\n",
    "    tss_end_2 = pd.to_numeric(tss_end_2, errors=\"coerce\")\n",
    "\n",
    "    # åˆ¤æ–·æœ‰ç„¡é›™æ–¹è³‡æ–™\n",
    "    if pd.notna(tss_start_1) and pd.notna(tss_start_2):\n",
    "        tss_start = min(tss_start_1, tss_start_2)\n",
    "    else:\n",
    "        tss_start = tss_start_1 if pd.notna(tss_start_1) else tss_start_2\n",
    "\n",
    "    if pd.notna(tss_end_1) and pd.notna(tss_end_2):\n",
    "        tss_end = max(tss_end_1, tss_end_2)\n",
    "    else:\n",
    "        tss_end = tss_end_1 if pd.notna(tss_end_1) else tss_end_2\n",
    "\n",
    "    return pd.Series({\"TSS_start\": int(tss_start), \"TSS_end\": int(tss_end)})\n",
    "\n",
    "merged_ref = merged.join(merged.apply(pick_reference, axis=1))\n",
    "\n",
    "# ============================================================\n",
    "# å»ºç«‹çµ±ä¸€ reference\n",
    "# ============================================================\n",
    "df_ref = merged_ref[merge_keys + [\"TSS_start\", \"TSS_end\"]].copy().drop_duplicates(ignore_index=True)\n",
    "\n",
    "print(f\"ğŸ“˜ Unified reference length (X1+X2): {len(df_ref)}\")\n",
    "\n",
    "# ============================================================\n",
    "# åŠ ä¸Š X3ï¼ˆç›´æ¥ concatï¼‰\n",
    "# ============================================================\n",
    "df_X3_ref = df_X3[[\"gene_name\", \"chr\", \"gene_start\", \"gene_end\", \"TSS_start\", \"TSS_end\", \"strand\"]]\n",
    "df_final_ref = pd.concat([df_ref, df_X3_ref], ignore_index=True)\n",
    "\n",
    "print(f\"ğŸ§© Final unified reference (with X3): {len(df_final_ref)}\")\n",
    "\n",
    "# ============================================================\n",
    "# å„²å­˜\n",
    "# ============================================================\n",
    "output_path = \"../preprocessed_data/CAGE-merged/reference_gene_table.tsv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df_final_ref.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"âœ… Saved reference table â†’ {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ref.isna().any().any()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
