{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged train+val and merged info and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 rows: 16284, X2 rows: 16284\n",
      "✅ X1 and X2 gene metadata are COMPLETELY identical.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 路徑設定\n",
    "# ============================================================\n",
    "base = \"../ML4G_Project_1_Data/CAGE-train/CAGE-train\"\n",
    "\n",
    "files = {\n",
    "    \"X1_train\": os.path.join(base, \"X1_train_info.tsv\"),\n",
    "    \"X1_val\":   os.path.join(base, \"X1_val_info.tsv\"),\n",
    "    \"X2_train\": os.path.join(base, \"X2_train_info.tsv\"),\n",
    "    \"X2_val\":   os.path.join(base, \"X2_val_info.tsv\"),\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# 載入並合併 X1 / X2\n",
    "# ============================================================\n",
    "def load_and_concat(train_path, val_path):\n",
    "    df_train = pd.read_csv(train_path, sep=\"\\t\")\n",
    "    df_val = pd.read_csv(val_path, sep=\"\\t\")\n",
    "    df = pd.concat([df_train, df_val], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "df_X1 = load_and_concat(files[\"X1_train\"], files[\"X1_val\"])\n",
    "df_X2 = load_and_concat(files[\"X2_train\"], files[\"X2_val\"])\n",
    "\n",
    "# ============================================================\n",
    "# 指定要比較的欄位\n",
    "# ============================================================\n",
    "cols_to_check = [\"gene_name\", \"chr\", \"gene_start\", \"gene_end\", \"TSS_start\", \"TSS_end\", \"strand\"]\n",
    "\n",
    "df1 = df_X1[cols_to_check].copy().reset_index(drop=True)\n",
    "df2 = df_X2[cols_to_check].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"X1 rows: {len(df1)}, X2 rows: {len(df2)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 比較資料列是否完全一致\n",
    "# ============================================================\n",
    "# 方法1：直接用 pandas.equals()\n",
    "same_structure = df1.equals(df2)\n",
    "\n",
    "if same_structure:\n",
    "    print(\"✅ X1 and X2 gene metadata are COMPLETELY identical.\")\n",
    "else:\n",
    "    print(\"❌ Differences found between X1 and X2 gene annotations.\")\n",
    "\n",
    "    # 檢查差異筆數與 gene_name 不同之處\n",
    "    merged = df1.merge(df2, on=cols_to_check, how=\"outer\", indicator=True)\n",
    "    diff = merged[merged[\"_merge\"] != \"both\"]\n",
    "\n",
    "    print(f\"⚠️ Number of differing entries: {len(diff)}\")\n",
    "    print(\"Sample differences:\")\n",
    "    print(diff.head(10))\n",
    "\n",
    "    # 如果你只想知道哪邊少了哪些基因：\n",
    "    missing_in_X2 = df1.merge(df2, on=cols_to_check, how=\"left\", indicator=True)\n",
    "    missing_in_X2 = missing_in_X2[missing_in_X2[\"_merge\"] == \"left_only\"]\n",
    "    print(f\"\\n🧩 Genes in X1 but not in X2: {len(missing_in_X2)}\")\n",
    "    print(missing_in_X2.head())\n",
    "\n",
    "    missing_in_X1 = df2.merge(df1, on=cols_to_check, how=\"left\", indicator=True)\n",
    "    missing_in_X1 = missing_in_X1[missing_in_X1[\"_merge\"] == \"left_only\"]\n",
    "    print(f\"\\n🧩 Genes in X2 but not in X1: {len(missing_in_X1)}\")\n",
    "    print(missing_in_X1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded: X1(16284), X2(16284), X3(1984)\n",
      "🔗 Merged X1 & X2: 16284 entries\n",
      "📘 Unified reference length (X1+X2): 16284\n",
      "🧩 Final unified reference (with X3): 18268\n",
      "✅ Saved reference table → ../preprocessed_data/CAGE-merged/reference_gene_table.tsv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# 路徑設定\n",
    "# ============================================================\n",
    "base = \"../ML4G_Project_1_Data/CAGE-train/CAGE-train\"\n",
    "\n",
    "X1_train = os.path.join(base, \"X1_train_info.tsv\")\n",
    "X1_val   = os.path.join(base, \"X1_val_info.tsv\")\n",
    "X2_train = os.path.join(base, \"X2_train_info.tsv\")\n",
    "X2_val   = os.path.join(base, \"X2_val_info.tsv\")\n",
    "X3_test  = os.path.join(base, \"X3_test_info.tsv\")\n",
    "\n",
    "# ============================================================\n",
    "# 載入與合併\n",
    "# ============================================================\n",
    "def load_concat(train, val):\n",
    "    df1 = pd.read_csv(train, sep=\"\\t\")\n",
    "    df2 = pd.read_csv(val, sep=\"\\t\")\n",
    "    return pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df_X1 = load_concat(X1_train, X1_val)\n",
    "df_X2 = load_concat(X2_train, X2_val)\n",
    "df_X3 = pd.read_csv(X3_test, sep=\"\\t\")\n",
    "\n",
    "print(f\"✅ Loaded: X1({len(df_X1)}), X2({len(df_X2)}), X3({len(df_X3)})\")\n",
    "\n",
    "# ============================================================\n",
    "# 準備合併用的 key\n",
    "# ============================================================\n",
    "merge_keys = [\"gene_name\", \"chr\", \"gene_start\", \"gene_end\", \"strand\"]\n",
    "\n",
    "merged = df_X1.merge(\n",
    "    df_X2,\n",
    "    on=merge_keys,\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_X1\", \"_X2\"),\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "print(f\"🔗 Merged X1 & X2: {len(merged)} entries\")\n",
    "\n",
    "# ============================================================\n",
    "# 若兩者 TSS 不同 → 用 min/max 統一\n",
    "# ============================================================\n",
    "def pick_reference(row):\n",
    "    # 若有缺值 (某基因只出現在一邊)，取存在的值\n",
    "    tss_start_1, tss_start_2 = row.get(\"TSS_start_X1\"), row.get(\"TSS_start_X2\")\n",
    "    tss_end_1, tss_end_2 = row.get(\"TSS_end_X1\"), row.get(\"TSS_end_X2\")\n",
    "\n",
    "    # 將缺失值視為 NaN 處理\n",
    "    tss_start_1 = pd.to_numeric(tss_start_1, errors=\"coerce\")\n",
    "    tss_start_2 = pd.to_numeric(tss_start_2, errors=\"coerce\")\n",
    "    tss_end_1 = pd.to_numeric(tss_end_1, errors=\"coerce\")\n",
    "    tss_end_2 = pd.to_numeric(tss_end_2, errors=\"coerce\")\n",
    "\n",
    "    # 判斷有無雙方資料\n",
    "    if pd.notna(tss_start_1) and pd.notna(tss_start_2):\n",
    "        tss_start = min(tss_start_1, tss_start_2)\n",
    "    else:\n",
    "        tss_start = tss_start_1 if pd.notna(tss_start_1) else tss_start_2\n",
    "\n",
    "    if pd.notna(tss_end_1) and pd.notna(tss_end_2):\n",
    "        tss_end = max(tss_end_1, tss_end_2)\n",
    "    else:\n",
    "        tss_end = tss_end_1 if pd.notna(tss_end_1) else tss_end_2\n",
    "\n",
    "    return pd.Series({\"TSS_start\": int(tss_start), \"TSS_end\": int(tss_end)})\n",
    "\n",
    "merged_ref = merged.join(merged.apply(pick_reference, axis=1))\n",
    "\n",
    "# ============================================================\n",
    "# 建立統一 reference\n",
    "# ============================================================\n",
    "df_ref = merged_ref[merge_keys + [\"TSS_start\", \"TSS_end\"]].copy().drop_duplicates(ignore_index=True)\n",
    "\n",
    "print(f\"📘 Unified reference length (X1+X2): {len(df_ref)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 加上 X3（直接 concat）\n",
    "# ============================================================\n",
    "df_X3_ref = df_X3[[\"gene_name\", \"chr\", \"gene_start\", \"gene_end\", \"TSS_start\", \"TSS_end\", \"strand\"]]\n",
    "df_final_ref = pd.concat([df_ref, df_X3_ref], ignore_index=True)\n",
    "\n",
    "print(f\"🧩 Final unified reference (with X3): {len(df_final_ref)}\")\n",
    "\n",
    "# ============================================================\n",
    "# 儲存\n",
    "# ============================================================\n",
    "output_path = \"../preprocessed_data/CAGE-merged/reference_gene_table.tsv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df_final_ref.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"✅ Saved reference table → {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_ref.isna().any().any()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
